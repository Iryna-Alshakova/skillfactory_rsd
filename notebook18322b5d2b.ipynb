{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install datasets\n#!pip install tokenizers==0.10.0rc1\n#!pip install wandb","metadata":{"id":"rJnHQn4htNIF","outputId":"a9944aca-2fa0-4a26-f0ce-1b32ccd9705a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nimport datasets\nimport tokenizers\nimport wandb\nfrom tqdm.auto import tqdm\n\nimport matplotlib.pyplot as plt","metadata":{"id":"IGJsIqgRtEn-","execution":{"iopub.status.busy":"2021-10-05T15:17:01.868601Z","iopub.execute_input":"2021-10-05T15:17:01.869215Z","iopub.status.idle":"2021-10-05T15:17:01.875501Z","shell.execute_reply.started":"2021-10-05T15:17:01.869156Z","shell.execute_reply":"2021-10-05T15:17:01.874783Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"text_dataset = datasets.load_dataset(\"imdb\")","metadata":{"id":"LUvFcan-tG5e","outputId":"3ab48820-0022-496a-ee5d-48f313eae75b","execution":{"iopub.status.busy":"2021-10-05T15:17:01.876863Z","iopub.execute_input":"2021-10-05T15:17:01.877549Z","iopub.status.idle":"2021-10-05T15:17:03.290678Z","shell.execute_reply.started":"2021-10-05T15:17:01.877505Z","shell.execute_reply":"2021-10-05T15:17:03.289807Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**IMDB** - это датасет по классификации эмоциональной окраски. Вам нужно предсказать положительный ли отзыв к фильму по его тексту. Это довольно простая задача и она хорошо решается даже линейными моделями. Для доступа к нему мы используем библиотеку `datasets` - она содержит в себе много интересных текстовых датасетов.\n\nТренировочная и тстовая части IMDB достаточно большие - каждая состоит из 25 тысяч примеров.","metadata":{"id":"1JrixvHI6teb"}},{"cell_type":"code","source":"text_dataset","metadata":{"id":"GL4eJ8hcwHA_","execution":{"iopub.status.busy":"2021-10-05T14:56:55.139163Z","iopub.execute_input":"2021-10-05T14:56:55.139969Z","iopub.status.idle":"2021-10-05T14:56:55.146934Z","shell.execute_reply.started":"2021-10-05T14:56:55.139933Z","shell.execute_reply":"2021-10-05T14:56:55.146141Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Как мы видим, классы сбалансированны, что позволяет использовать accuracy как простую и интерпретируемую метрику, хорошо показывающую качество модели.","metadata":{"id":"oUVSXa2r7oak"}},{"cell_type":"code","source":"train_labels = [e['label'] for e in text_dataset['train']]\nplt.hist(train_labels)\nplt.show()","metadata":{"id":"wbCkXd6_7VU_","execution":{"iopub.status.busy":"2021-10-05T14:57:04.305114Z","iopub.execute_input":"2021-10-05T14:57:04.305420Z","iopub.status.idle":"2021-10-05T14:57:05.843335Z","shell.execute_reply.started":"2021-10-05T14:57:04.305387Z","shell.execute_reply":"2021-10-05T14:57:05.842515Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"text_dataset['train']","metadata":{"id":"o04VWlLvwpDd","execution":{"iopub.status.busy":"2021-10-05T14:57:06.691169Z","iopub.execute_input":"2021-10-05T14:57:06.691658Z","iopub.status.idle":"2021-10-05T14:57:06.696433Z","shell.execute_reply.started":"2021-10-05T14:57:06.691614Z","shell.execute_reply":"2021-10-05T14:57:06.695701Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text_dataset['train']['text'][0]","metadata":{"id":"SdqU7ZTiwrC9","execution":{"iopub.status.busy":"2021-10-05T14:57:07.108024Z","iopub.execute_input":"2021-10-05T14:57:07.108680Z","iopub.status.idle":"2021-10-05T14:57:07.170072Z","shell.execute_reply.started":"2021-10-05T14:57:07.108634Z","shell.execute_reply":"2021-10-05T14:57:07.169074Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Classification using a linear model\n\nЛинейная модель - очень сильный бейзлайн и в некоторых задачах классификации вам даже не надо идти дальше линейной модели - она уже достаточно хороша. А также её можно написать менее чем в 10 строчекю Поэтому всегда стоит начинать решение любой задачи с ленейного бейзлайна.\n\nДавайте вспомним библиотеку `sklearn` и напишем линейную модельку. Для векторизации текста мы будем использовать `TfidfVectorizer`, а в качестве модели `LogisticRegression`.\n","metadata":{"id":"bVemry0mziTa"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"id":"fMU_c9pKxe0d","execution":{"iopub.status.busy":"2021-10-05T15:17:37.114982Z","iopub.execute_input":"2021-10-05T15:17:37.115659Z","iopub.status.idle":"2021-10-05T15:17:37.132676Z","shell.execute_reply.started":"2021-10-05T15:17:37.115622Z","shell.execute_reply":"2021-10-05T15:17:37.131922Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# TASK 1.1: create TfidfVectorizer object and fit it on out training set texts\n# Our implementation is 2 lines\n# YOUR CODE STARTS\nvectorizer = TfidfVectorizer()\nvectorizer.fit(text_dataset['train']['text'])\n\n# YOUR CODE ENDS","metadata":{"id":"i5qXrSEXztwW","execution":{"iopub.status.busy":"2021-10-05T14:57:09.044213Z","iopub.execute_input":"2021-10-05T14:57:09.045064Z","iopub.status.idle":"2021-10-05T14:57:13.626713Z","shell.execute_reply.started":"2021-10-05T14:57:09.045022Z","shell.execute_reply":"2021-10-05T14:57:13.626063Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# TASK 1.2:\n# 1. convert your texts to tf-idf vectors using .transform (training texts and test texts too)\n# 2. convert your labels into numpy arrays (both training and test labels)\n# Or implementatin is 4 lines\n\n# YOUR CODE STARTS\nX_train = vectorizer.transform(text_dataset['train']['text']).toarray()\ny_train = text_dataset['train']['label']\n\nX_test = vectorizer.transform(text_dataset['test']['text']).toarray()\ny_test = text_dataset['test']['label']\n# YOUR CODE ENDS","metadata":{"id":"RRkJP8yz2KPP","execution":{"iopub.status.busy":"2021-10-05T14:57:16.017447Z","iopub.execute_input":"2021-10-05T14:57:16.018343Z","iopub.status.idle":"2021-10-05T14:57:47.080733Z","shell.execute_reply.started":"2021-10-05T14:57:16.018299Z","shell.execute_reply":"2021-10-05T14:57:47.079715Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train, y_train","metadata":{"id":"_FAAuos63UtS","execution":{"iopub.status.busy":"2021-10-05T14:57:47.082151Z","iopub.execute_input":"2021-10-05T14:57:47.082510Z","iopub.status.idle":"2021-10-05T14:57:47.100986Z","shell.execute_reply.started":"2021-10-05T14:57:47.082477Z","shell.execute_reply":"2021-10-05T14:57:47.100330Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# TASK 1.3: create LogisticRegression model object and fit the model\n# Our implementation is 2 lines\n# YOUR CODE STARTS\n\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X_train, y_train)\n\n\n# YOUR CODE ENDS","metadata":{"id":"gnWo2pLB1ho0","execution":{"iopub.status.busy":"2021-10-05T14:58:06.493752Z","iopub.execute_input":"2021-10-05T14:58:06.494205Z","iopub.status.idle":"2021-10-05T14:59:02.878438Z","shell.execute_reply.started":"2021-10-05T14:58:06.494172Z","shell.execute_reply":"2021-10-05T14:59:02.877373Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"А теперь мы используем нашу модель для того, чтобы предсказать классы на тестовом сете и считаем accuracy.","metadata":{"id":"RJRuIbVrqDpR"}},{"cell_type":"code","source":"predictions = model.predict(X_test)\n\nprint(type(predictions))\nprint(type(y_test))","metadata":{"id":"ZKCOA3SE3kSK","execution":{"iopub.status.busy":"2021-10-05T14:59:11.161278Z","iopub.execute_input":"2021-10-05T14:59:11.162137Z","iopub.status.idle":"2021-10-05T14:59:14.835084Z","shell.execute_reply.started":"2021-10-05T14:59:11.162090Z","shell.execute_reply":"2021-10-05T14:59:14.834042Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# note that we can use vector operations, because we deal with numpy tensors\naccuracy = (predictions == y_test).mean()\naccuracy","metadata":{"id":"pyO4CMzB3jds","execution":{"iopub.status.busy":"2021-10-05T14:59:14.837369Z","iopub.execute_input":"2021-10-05T14:59:14.838155Z","iopub.status.idle":"2021-10-05T14:59:14.852152Z","shell.execute_reply.started":"2021-10-05T14:59:14.838096Z","shell.execute_reply":"2021-10-05T14:59:14.851192Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**OMG so accurate, much machine learning**","metadata":{"id":"AENaKt7huHd1"}},{"cell_type":"markdown","source":"Давайте предскажем позитивны ли такие комментарии:","metadata":{"id":"5NpZecL4qqI5"}},{"cell_type":"code","source":"positive_comment = 'This movie is awesome!'\n\nvec = vectorizer.transform([positive_comment])\nmodel.predict(vec)","metadata":{"id":"XKlLVQUqsRlI","execution":{"iopub.status.busy":"2021-10-05T14:59:29.532441Z","iopub.execute_input":"2021-10-05T14:59:29.532760Z","iopub.status.idle":"2021-10-05T14:59:29.542309Z","shell.execute_reply.started":"2021-10-05T14:59:29.532729Z","shell.execute_reply":"2021-10-05T14:59:29.541371Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"negative_comment = 'This movie is awful!'\n\nvec = vectorizer.transform([negative_comment])\nmodel.predict(vec)","metadata":{"id":"CHtq-453t2Gb","execution":{"iopub.status.busy":"2021-10-05T14:59:32.624180Z","iopub.execute_input":"2021-10-05T14:59:32.625053Z","iopub.status.idle":"2021-10-05T14:59:32.632344Z","shell.execute_reply.started":"2021-10-05T14:59:32.625011Z","shell.execute_reply":"2021-10-05T14:59:32.631592Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Как мы увидели, даже такая простая модель может хорошо классифицировать текст (accuracy 0.9 - это довольно много, тк выборка сбалансированна).\n\nКстати, использование модели LinearSVM обычно работает даже лучше, чем логистическая регрессия. Рекомендуем попробовать и сравнить.\n\nЧто такое SVM: [тык](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)\n\nЕщё один простой метод улучшить линейную модель - использовать n-gram в вашем TF-IDF. Не забудьте указать параметр `max_features` (хорошое число 50 000), а то при большом количестве фичей модель может начать переобучаться.","metadata":{"id":"Xm2GycUTTjgW"}},{"cell_type":"markdown","source":"## LinearSVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nsvm_model = LinearSVC(random_state=0).fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:09:33.191967Z","iopub.execute_input":"2021-10-05T15:09:33.192552Z","iopub.status.idle":"2021-10-05T15:09:43.315084Z","shell.execute_reply.started":"2021-10-05T15:09:33.192500Z","shell.execute_reply":"2021-10-05T15:09:43.314041Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"predictions = svm_model.predict(X_test)\naccuracy = (predictions == y_test).mean()\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:09:51.975904Z","iopub.execute_input":"2021-10-05T15:09:51.976256Z","iopub.status.idle":"2021-10-05T15:09:54.728426Z","shell.execute_reply.started":"2021-10-05T15:09:51.976220Z","shell.execute_reply":"2021-10-05T15:09:54.727256Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"positive_comment = 'This movie is awesome!'\n\nvec = vectorizer.transform([positive_comment])\nmodel.predict(vec)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:10:03.767365Z","iopub.execute_input":"2021-10-05T15:10:03.767712Z","iopub.status.idle":"2021-10-05T15:10:03.778805Z","shell.execute_reply.started":"2021-10-05T15:10:03.767679Z","shell.execute_reply":"2021-10-05T15:10:03.777996Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"negative_comment = 'This movie is awful!'\n\nvec = vectorizer.transform([negative_comment])\nmodel.predict(vec)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:10:10.421275Z","iopub.execute_input":"2021-10-05T15:10:10.422077Z","iopub.status.idle":"2021-10-05T15:10:10.431328Z","shell.execute_reply.started":"2021-10-05T15:10:10.422037Z","shell.execute_reply":"2021-10-05T15:10:10.430595Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## ngrams","metadata":{}},{"cell_type":"code","source":"vectorizer_n = TfidfVectorizer(ngram_range=(1,2), max_features=50000)\nvectorizer_n.fit(text_dataset['train']['text'])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:17:48.053562Z","iopub.execute_input":"2021-10-05T15:17:48.054127Z","iopub.status.idle":"2021-10-05T15:18:08.493612Z","shell.execute_reply.started":"2021-10-05T15:17:48.054082Z","shell.execute_reply":"2021-10-05T15:18:08.492807Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train = vectorizer_n.transform(text_dataset['train']['text']).toarray()\ny_train = text_dataset['train']['label']\n\nX_test = vectorizer_n.transform(text_dataset['test']['text']).toarray()\ny_test = text_dataset['test']['label']","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:18:11.959977Z","iopub.execute_input":"2021-10-05T15:18:11.960634Z","iopub.status.idle":"2021-10-05T15:18:51.121236Z","shell.execute_reply.started":"2021-10-05T15:18:11.960589Z","shell.execute_reply":"2021-10-05T15:18:51.120491Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(X_train[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:19:28.005653Z","iopub.execute_input":"2021-10-05T15:19:28.006589Z","iopub.status.idle":"2021-10-05T15:19:28.013297Z","shell.execute_reply.started":"2021-10-05T15:19:28.006540Z","shell.execute_reply":"2021-10-05T15:19:28.012503Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nsvm_model = LinearSVC(random_state=0).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:19:31.425926Z","iopub.execute_input":"2021-10-05T15:19:31.426238Z","iopub.status.idle":"2021-10-05T15:19:39.767286Z","shell.execute_reply.started":"2021-10-05T15:19:31.426204Z","shell.execute_reply":"2021-10-05T15:19:39.766378Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"predictions = svm_model.predict(X_test)\naccuracy = (predictions == y_test).mean()\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:20:17.114334Z","iopub.execute_input":"2021-10-05T15:20:17.115085Z","iopub.status.idle":"2021-10-05T15:20:19.075979Z","shell.execute_reply.started":"2021-10-05T15:20:17.115040Z","shell.execute_reply":"2021-10-05T15:20:19.075008Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"positive_comment = 'This movie is awesome!'\n\nvec = vectorizer_n.transform([positive_comment])\nsvm_model.predict(vec)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:20:43.066451Z","iopub.execute_input":"2021-10-05T15:20:43.066911Z","iopub.status.idle":"2021-10-05T15:20:43.075045Z","shell.execute_reply.started":"2021-10-05T15:20:43.066882Z","shell.execute_reply":"2021-10-05T15:20:43.074092Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"negative_comment = 'This movie is awful!'\n\nvec = vectorizer_n.transform([negative_comment])\nsvm_model.predict(vec)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T15:20:56.486796Z","iopub.execute_input":"2021-10-05T15:20:56.487098Z","iopub.status.idle":"2021-10-05T15:20:56.496501Z","shell.execute_reply.started":"2021-10-05T15:20:56.487069Z","shell.execute_reply":"2021-10-05T15:20:56.495573Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}